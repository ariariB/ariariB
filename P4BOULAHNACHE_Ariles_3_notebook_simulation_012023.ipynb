{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fd51688",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import joblib\n",
    "\n",
    "import warnings\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b74e63df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importation du jeu de donnée\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_row', None)\n",
    "\n",
    "# Pour charger le DataFrame à partir du fichier Joblib\n",
    "df_cluster_sample = joblib.load('df_cluster_sample.joblib')\n",
    "\n",
    "rfm_data = joblib.load('rfm_data.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "914a1352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23010, 36)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cluster_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbc13e15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['order_id',\n",
       " 'order_item_id',\n",
       " 'product_id',\n",
       " 'seller_id',\n",
       " 'price',\n",
       " 'freight_value',\n",
       " 'product_category_name',\n",
       " 'payment_type',\n",
       " 'payment_installments',\n",
       " 'payment_value',\n",
       " 'customer_id',\n",
       " 'order_approved_at',\n",
       " 'customer_unique_id',\n",
       " 'customer_zip_code_prefix',\n",
       " 'customer_city',\n",
       " 'customer_state',\n",
       " 'review_score',\n",
       " 'seller_zip_code_prefix',\n",
       " 'seller_city',\n",
       " 'seller_state',\n",
       " 'customer_geo_lat',\n",
       " 'customer_geo_lng',\n",
       " 'seller_geo_lat',\n",
       " 'seller_geo_lng',\n",
       " 'time_between_orders_same_customer',\n",
       " 'days_between_orders_same_customer',\n",
       " 'hours_between_orders_same_customer',\n",
       " 'time_between_orders_all',\n",
       " 'days_between_orders_all',\n",
       " 'hours_between_orders_all',\n",
       " 'order_month',\n",
       " 'day_of_week',\n",
       " 'day_of_month',\n",
       " 'distance',\n",
       " 'cluster',\n",
       " 'Recency']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df_cluster_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd018f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697616e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARI à 2017-01-19 23:05:27: 0.8449112242215691\n",
      "ARI à 2017-02-02 23:05:27: 0.7670035897802935\n",
      "Le modèle M0 devient obsolète à 2017-02-02 23:05:27\n",
      "Le modèle M0 a été réentraîné.\n",
      "Réentraînement de M1 à 2017-02-03 23:05:27\n",
      "Le modèle M1 a été réentraîné.\n",
      "Réentraînement de M2 à 2017-02-03 23:05:27\n",
      "Le modèle M2 a été réentraîné.\n",
      "ARI à 2017-02-16 23:05:27: 0.4241338565277158\n",
      "Le modèle M0 devient obsolète à 2017-02-16 23:05:27\n",
      "Le modèle M0 a été réentraîné.\n",
      "Réentraînement de M1 à 2017-02-17 23:05:27\n",
      "Le modèle M1 a été réentraîné.\n",
      "Réentraînement de M2 à 2017-02-17 23:05:27\n",
      "Le modèle M2 a été réentraîné.\n",
      "ARI à 2017-03-02 23:05:27: 0.4632685453059713\n",
      "Le modèle M0 devient obsolète à 2017-03-02 23:05:27\n",
      "Le modèle M0 a été réentraîné.\n",
      "Réentraînement de M1 à 2017-03-03 23:05:27\n",
      "Le modèle M1 a été réentraîné.\n",
      "Réentraînement de M2 à 2017-03-03 23:05:27\n",
      "Le modèle M2 a été réentraîné.\n",
      "ARI à 2017-03-16 23:05:27: 0.4103529443188131\n",
      "Le modèle M0 devient obsolète à 2017-03-16 23:05:27\n",
      "Le modèle M0 a été réentraîné.\n",
      "Réentraînement de M1 à 2017-03-17 23:05:27\n",
      "Le modèle M1 a été réentraîné.\n",
      "Réentraînement de M2 à 2017-03-17 23:05:27\n",
      "Le modèle M2 a été réentraîné.\n",
      "ARI à 2017-03-30 23:05:27: 0.6091530542478352\n",
      "Le modèle M0 devient obsolète à 2017-03-30 23:05:27\n",
      "Le modèle M0 a été réentraîné.\n",
      "Réentraînement de M1 à 2017-03-31 23:05:27\n",
      "Le modèle M1 a été réentraîné.\n",
      "Réentraînement de M2 à 2017-03-31 23:05:27\n",
      "Le modèle M2 a été réentraîné.\n",
      "ARI à 2017-04-13 23:05:27: 0.916761320102926\n",
      "Réentraînement de M1 à 2017-04-14 23:05:27\n",
      "Le modèle M1 a été réentraîné.\n",
      "Réentraînement de M2 à 2017-04-14 23:05:27\n",
      "Le modèle M2 a été réentraîné.\n",
      "ARI à 2017-04-27 23:05:27: 0.9360229521678242\n",
      "Réentraînement de M1 à 2017-04-28 23:05:27\n",
      "Le modèle M1 a été réentraîné.\n",
      "Réentraînement de M2 à 2017-04-28 23:05:27\n",
      "Le modèle M2 a été réentraîné.\n",
      "ARI à 2017-05-11 23:05:27: 0.6059512672958308\n",
      "Le modèle M0 devient obsolète à 2017-05-11 23:05:27\n",
      "Le modèle M0 a été réentraîné.\n",
      "Réentraînement de M1 à 2017-05-12 23:05:27\n",
      "Le modèle M1 a été réentraîné.\n",
      "Réentraînement de M2 à 2017-05-12 23:05:27\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Charger le DataFrame initial (en supposant que vous avez un DataFrame nommé df_cluster_sample)\n",
    "df = df_cluster_sample.copy()\n",
    "\n",
    "# Ajouter une colonne 'year' basée sur 'order_approved_at'\n",
    "df['year'] = df['order_approved_at'].dt.year\n",
    "\n",
    "# Filtrer les données pour les années 2017 et 2018\n",
    "df = df[(df['year'] == 2017) | (df['year'] == 2018)]\n",
    "# Colonnes à supprimer\n",
    "colonnes_a_supprimer = ['seller_zip_code_prefix', 'seller_city', 'seller_state', 'customer_geo_lat', 'customer_geo_lng',\n",
    "                   'seller_geo_lat', 'seller_geo_lng', 'time_between_orders_same_customer',\n",
    "                   'days_between_orders_same_customer', 'hours_between_orders_same_customer',\n",
    "                   'time_between_orders_all', 'days_between_orders_all', 'hours_between_orders_all',\n",
    "                   'order_id', 'product_id', 'seller_id', 'customer_id', 'customer_unique_id']\n",
    "\n",
    "# Supprimer les colonnes spécifiées\n",
    "df = df.drop(columns=colonnes_a_supprimer)\n",
    "\n",
    "# Fonction pour créer un ensemble de données jusqu'à une date donnée\n",
    "def creer_ensemble_de_donnees(df, date_fin, scaler, encodeur, noms_caracteristiques_de_base):\n",
    "    ensemble_de_donnees = df[df['order_approved_at'] <= date_fin].drop('order_approved_at', axis=1)\n",
    "    \n",
    "    # Séparer les colonnes numériques et catégorielles\n",
    "    colonnes_numeriques = ensemble_de_donnees.select_dtypes(include=np.number).columns\n",
    "    colonnes_catégorielles = ensemble_de_donnees.select_dtypes(exclude=np.number).columns\n",
    "\n",
    "    # Ajuster et transformer les colonnes numériques\n",
    "    ensemble_de_donnees[colonnes_numeriques] = scaler.fit_transform(ensemble_de_donnees[colonnes_numeriques])\n",
    "\n",
    "    # Transformer les colonnes catégorielles et créer un nouveau DataFrame\n",
    "    cat_transformed = pd.DataFrame(encodeur.fit_transform(ensemble_de_donnees[colonnes_catégorielles]),\n",
    "                                   columns=encodeur.get_feature_names_out(colonnes_catégorielles), index=ensemble_de_donnees.index)\n",
    "\n",
    "    # Concaténer les colonnes numériques et catégorielles transformées\n",
    "    ensemble_de_donnees = pd.concat([ensemble_de_donnees[colonnes_numeriques], cat_transformed], axis=1)\n",
    "\n",
    "    # Assurer la cohérence dans les noms des caractéristiques\n",
    "    ensemble_de_donnees.columns = ensemble_de_donnees.columns.astype(str)\n",
    "\n",
    "    # Obtenir les caractéristiques manquantes des noms de caractéristiques de base\n",
    "    caractéristiques_manquantes = set(noms_caracteristiques_de_base) - set(ensemble_de_donnees.columns)\n",
    "\n",
    "    # Ajouter les caractéristiques manquantes avec des zéros comme valeurs\n",
    "    for caractéristique in caractéristiques_manquantes:\n",
    "        ensemble_de_donnees[caractéristique] = 0\n",
    "\n",
    "    # Réorganiser les colonnes pour correspondre aux noms de caractéristiques de base\n",
    "    ensemble_de_donnees = ensemble_de_donnees[noms_caracteristiques_de_base]\n",
    "\n",
    "    return ensemble_de_donnees\n",
    "\n",
    "# Entraînement initial du modèle sur F0 (en supposant que T0 est le début du jeu de données)\n",
    "scaler_m0 = StandardScaler()\n",
    "encodeur_m0 = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Ajuster encodeur_m0 sur l'ensemble du jeu de données pour obtenir les noms de caractéristiques\n",
    "colonnes_catégorielles = df.select_dtypes(exclude=np.number).columns\n",
    "encodeur_m0.fit(df[colonnes_catégorielles])\n",
    "\n",
    "# Initialize meilleur_ari before the loop\n",
    "meilleur_ari = 0\n",
    "\n",
    "F0 = creer_ensemble_de_donnees(df, df['order_approved_at'].min() + timedelta(weeks=2), scaler_m0, encodeur_m0, df.columns)  # 2 semaines à partir de la date de début\n",
    "\n",
    "# Convertir tous les noms de colonnes en chaînes\n",
    "F0.columns = F0.columns.astype(str)\n",
    "\n",
    "# Initialiser les modèles M0, M1, M2 en dehors de la boucle\n",
    "M0 = KMeans(n_clusters=6)\n",
    "M1 = KMeans(n_clusters=6)\n",
    "M2 = KMeans(n_clusters=6)\n",
    "\n",
    "# Ajuster M0 sur F0 (ensemble de données initial)\n",
    "M0.fit(F0)\n",
    "c0_m0 = M0.predict(F0)\n",
    "\n",
    "# Initialiser les flags pour réentrainer M0, M1, M2\n",
    "retrain_m0 = False\n",
    "retrain_m1 = False\n",
    "retrain_m2 = False\n",
    "\n",
    "# Initialiser la date_actuelle et jours_entre_les_simulations\n",
    "date_actuelle = df['order_approved_at'].min() + timedelta(weeks=2)\n",
    "jours_entre_les_simulations = 14\n",
    "\n",
    "while date_actuelle <= df['order_approved_at'].max():\n",
    "    # Créer l'ensemble de données Fi\n",
    "    Fi = creer_ensemble_de_donnees(df, date_actuelle, scaler_m0, encodeur_m0, df.columns)\n",
    "    \n",
    "    # Convertir tous les noms de colonnes en chaînes\n",
    "    Fi.columns = Fi.columns.astype(str)\n",
    "\n",
    "    # Entraîner un nouveau modèle Mi sur Fi\n",
    "    scaler_mi = StandardScaler()\n",
    "    encodeur_mi = OneHotEncoder(sparse=False)\n",
    "\n",
    "    # Utiliser les noms de caractéristiques de l'encodeur_m0 pour assurer la cohérence\n",
    "    encodeur_mi.fit(df[colonnes_catégorielles])\n",
    "\n",
    "    Fi_mise_a_l_echelle = creer_ensemble_de_donnees(df, date_actuelle, scaler_mi, encodeur_mi, df.columns)\n",
    "\n",
    "    # Assurer la cohérence dans les noms des caractéristiques\n",
    "    Fi_mise_a_l_echelle.columns = Fi_mise_a_l_echelle.columns.astype(str)\n",
    "\n",
    "    # Obtenir les caractéristiques manquantes du modèle initial\n",
    "    caractéristiques_manquantes = set(F0.columns) - set(Fi_mise_a_l_echelle.columns)\n",
    "\n",
    "    # Ajouter les caractéristiques manquantes avec des zéros comme valeurs\n",
    "    for caractéristique in caractéristiques_manquantes:\n",
    "        Fi_mise_a_l_echelle[caractéristique] = 0\n",
    "\n",
    "    # Réorganiser les colonnes pour correspondre au modèle initial\n",
    "    Fi_mise_a_l_echelle = Fi_mise_a_l_echelle[F0.columns]\n",
    "\n",
    "    Mi = KMeans(n_clusters=5)\n",
    "    Mi.fit(Fi_mise_a_l_echelle)\n",
    "    c1_mi = Mi.predict(Fi_mise_a_l_echelle)\n",
    "\n",
    "    # Prédire les clusters de Fi en utilisant le modèle initial M0\n",
    "    c1_m0 = M0.predict(Fi_mise_a_l_echelle)\n",
    "\n",
    "    # Calculer l'ARI\n",
    "    ari = adjusted_rand_score(c1_mi, c1_m0)\n",
    "    print(f\"ARI à {date_actuelle}: {ari}\")\n",
    "\n",
    "    # Mettre à jour le meilleur ARI et sa date si nécessaire\n",
    "    if ari > meilleur_ari:\n",
    "        meilleur_ari = ari\n",
    "        meilleure_date = date_actuelle\n",
    "\n",
    "    # Déterminer si le modèle M0 devient obsolète\n",
    "    if ari < 0.8:\n",
    "        print(f\"Le modèle M0 devient obsolète à {date_actuelle}\")\n",
    "        F0_mise_a_l_echelle = creer_ensemble_de_donnees(df, date_actuelle, scaler_m0, encodeur_m0, df.columns)\n",
    "        \n",
    "        # Convertir tous les noms de colonnes en chaînes\n",
    "        F0_mise_a_l_echelle.columns = F0_mise_a_l_echelle.columns.astype(str)\n",
    "        \n",
    "        M0.fit(F0_mise_a_l_echelle)\n",
    "        print(\"Le modèle M0 a été réentraîné.\")\n",
    "        # Réentraîner le modèle M1 dès le jour suivant\n",
    "        retrain_m1 = True\n",
    "\n",
    "    # Réentraîner le modèle M1 dès le jour suivant si nécessaire\n",
    "    if retrain_m1:\n",
    "        print(f\"Réentraînement de M1 à {date_actuelle + timedelta(days=1)}\")\n",
    "        Fi_mise_a_l_echelle = creer_ensemble_de_donnees(df, date_actuelle + timedelta(days=1), scaler_m0, encodeur_m0, df.columns)\n",
    "        \n",
    "        # Convertir tous les noms de colonnes en chaînes\n",
    "        Fi_mise_a_l_echelle.columns = Fi_mise_a_l_echelle.columns.astype(str)\n",
    "        \n",
    "        M1.fit(Fi_mise_a_l_echelle)\n",
    "        print(\"Le modèle M1 a été réentraîné.\")\n",
    "        # Réentraîner le modèle M2 dès le jour suivant\n",
    "        retrain_m2 = True\n",
    "\n",
    "    # Réentraîner le modèle M2 dès le jour suivant si nécessaire\n",
    "    if retrain_m2:\n",
    "        print(f\"Réentraînement de M2 à {date_actuelle + timedelta(days=1)}\")\n",
    "        Fi_mise_a_l_echelle = creer_ensemble_de_donnees(df, date_actuelle + timedelta(days=1), scaler_m0, encodeur_m0, df.columns)\n",
    "        \n",
    "        # Convertir tous les noms de colonnes en chaînes\n",
    "        Fi_mise_a_l_echelle.columns = Fi_mise_a_l_echelle.columns.astype(str)\n",
    "        \n",
    "        M2.fit(Fi_mise_a_l_echelle)\n",
    "        print(\"Le modèle M2 a été réentraîné.\")\n",
    "\n",
    "    # Passer à la période suivante\n",
    "    date_actuelle += timedelta(days=jours_entre_les_simulations)\n",
    "\n",
    "# Afficher le meilleur ARI et sa date correspondante après la boucle\n",
    "print(f\"Meilleur ARI : {meilleur_ari} à {meilleure_date}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddae8d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84193ace",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db51af7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARI at 2017-01-19 23:05:27: 0.8734704175602371\n",
      "ARI at 2017-02-02 23:05:27: 0.508866471473944\n",
      "M0 becomes obsolete at 2017-02-02 23:05:27\n",
      "M0 has been retrained.\n",
      "Retraining M1 at 2017-02-03 23:05:27\n",
      "M1 has been retrained.\n",
      "Retraining M2 at 2017-02-03 23:05:27\n",
      "M2 has been retrained.\n",
      "ARI at 2017-02-16 23:05:27: 0.4018665588958842\n",
      "M0 becomes obsolete at 2017-02-16 23:05:27\n",
      "M0 has been retrained.\n",
      "Retraining M1 at 2017-02-17 23:05:27\n",
      "M1 has been retrained.\n",
      "Retraining M2 at 2017-02-17 23:05:27\n",
      "M2 has been retrained.\n",
      "ARI at 2017-03-02 23:05:27: 0.5582824898944708\n",
      "M0 becomes obsolete at 2017-03-02 23:05:27\n",
      "M0 has been retrained.\n",
      "Retraining M1 at 2017-03-03 23:05:27\n",
      "M1 has been retrained.\n",
      "Retraining M2 at 2017-03-03 23:05:27\n",
      "M2 has been retrained.\n",
      "ARI at 2017-03-16 23:05:27: 0.4525065796278576\n",
      "M0 becomes obsolete at 2017-03-16 23:05:27\n",
      "M0 has been retrained.\n",
      "Retraining M1 at 2017-03-17 23:05:27\n",
      "M1 has been retrained.\n",
      "Retraining M2 at 2017-03-17 23:05:27\n",
      "M2 has been retrained.\n",
      "ARI at 2017-03-30 23:05:27: 0.491114027135456\n",
      "M0 becomes obsolete at 2017-03-30 23:05:27\n",
      "M0 has been retrained.\n",
      "Retraining M1 at 2017-03-31 23:05:27\n",
      "M1 has been retrained.\n",
      "Retraining M2 at 2017-03-31 23:05:27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def create_dataset(df, end_date, scaler, encoder, base_feature_names):\n",
    "    \"\"\"\n",
    "    Crée un ensemble de données jusqu'à une date donnée.\n",
    "    \n",
    "    Paramètres:\n",
    "    - df: DataFrame, DataFrame d'entrée.\n",
    "    - end_date: datetime, La date de fin.\n",
    "    - scaler: StandardScaler, le scaler pour les colonnes numériques.\n",
    "    - encoder: OneHotEncoder, l'encodeur pour les colonnes catégorielles.\n",
    "    - base_feature_names: liste, noms des caractéristiques de base.\n",
    "\n",
    "    Retourne:\n",
    "    DataFrame, l'ensemble de donnée créé.\n",
    "    \"\"\"\n",
    "    dataset = df[df['order_approved_at'] <= end_date].drop('order_approved_at', axis=1)\n",
    "\n",
    "    # Separate numeric and categorical columns\n",
    "    numeric_columns = dataset.select_dtypes(include=np.number).columns\n",
    "    categorical_columns = dataset.select_dtypes(exclude=np.number).columns\n",
    "\n",
    "    # Adjust and transform numeric columns\n",
    "    dataset[numeric_columns] = scaler.fit_transform(dataset[numeric_columns])\n",
    "\n",
    "    # Transform categorical columns and create a new DataFrame\n",
    "    cat_transformed = pd.DataFrame(encoder.fit_transform(dataset[categorical_columns]),\n",
    "                                   columns=encoder.get_feature_names_out(categorical_columns), index=dataset.index)\n",
    "\n",
    "    # Concatenate transformed numeric and categorical columns\n",
    "    dataset = pd.concat([dataset[numeric_columns], cat_transformed], axis=1)\n",
    "\n",
    "    # Ensure consistency in feature names \n",
    "    dataset.columns = dataset.columns.astype(str)\n",
    "\n",
    "    # Get missing features from base feature names\n",
    "    missing_features = set(base_feature_names) - set(dataset.columns)\n",
    "\n",
    "    # Add missing features with zero values\n",
    "    for feature in missing_features:\n",
    "        dataset[feature] = 0\n",
    "\n",
    "    # Reorder columns to match base feature names\n",
    "    dataset = dataset[base_feature_names]\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "# Load the initial DataFrame (assuming you have a DataFrame named df_cluster_sample)\n",
    "df = df_cluster_sample.copy()\n",
    "\n",
    "# Add a 'year' column based on 'order_approved_at'\n",
    "df['year'] = df['order_approved_at'].dt.year\n",
    "\n",
    "# Filter data for the years 2017 and 2018\n",
    "df = df[(df['year'] == 2017) | (df['year'] == 2018)]\n",
    "\n",
    "# Columns to delete\n",
    "columns_to_delete = ['seller_zip_code_prefix', 'seller_city', 'seller_state', 'customer_geo_lat', 'customer_geo_lng',\n",
    "                   'seller_geo_lat', 'seller_geo_lng', 'time_between_orders_same_customer',\n",
    "                   'days_between_orders_same_customer', 'hours_between_orders_same_customer',\n",
    "                   'time_between_orders_all', 'days_between_orders_all', 'hours_between_orders_all',\n",
    "                   'order_id', 'product_id', 'seller_id', 'customer_id', 'customer_unique_id']\n",
    "\n",
    "# Delete specified columns\n",
    "df = df.drop(columns=columns_to_delete)\n",
    "\n",
    "# Initial training of the model on F0 (assuming T0 is the start of the dataset)\n",
    "scaler_m0 = StandardScaler()\n",
    "encoder_m0 = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Adjust encoder_m0 on the entire dataset to get feature names\n",
    "categorical_columns = df.select_dtypes(exclude=np.number).columns\n",
    "encoder_m0.fit(df[categorical_columns])\n",
    "\n",
    "# Initialize best_ari before the loop\n",
    "best_ari = 0\n",
    "\n",
    "F0 = create_dataset(df, df['order_approved_at'].min() + timedelta(weeks=2), scaler_m0, encoder_m0, df.columns)\n",
    "\n",
    "# Convert all column names to strings\n",
    "F0.columns = F0.columns.astype(str)\n",
    "\n",
    "# Initialize models M0, M1, M2 outside the loop\n",
    "M0 = KMeans(n_clusters=6)\n",
    "M1 = KMeans(n_clusters=6)\n",
    "M2 = KMeans(n_clusters=6)\n",
    "\n",
    "# Train M0 on F0 (initial dataset)\n",
    "M0.fit(F0)\n",
    "c0_m0 = M0.predict(F0)\n",
    "\n",
    "# Initialize flags to retrain M0, M1, M2\n",
    "retrain_m0 = False\n",
    "retrain_m1 = False\n",
    "retrain_m2 = False\n",
    "\n",
    "# Initialize current_date and days_between_simulations\n",
    "current_date = df['order_approved_at'].min() + timedelta(weeks=2)\n",
    "days_between_simulations = 14\n",
    "\n",
    "while current_date <= df['order_approved_at'].max():\n",
    "    # Create dataset Fi\n",
    "    Fi = create_dataset(df, current_date, scaler_m0, encoder_m0, df.columns)\n",
    "\n",
    "    # Convert all column names to strings\n",
    "    Fi.columns = Fi.columns.astype(str)\n",
    "\n",
    "    # Train a new model Mi on Fi\n",
    "    scaler_mi = StandardScaler()\n",
    "    encoder_mi = OneHotEncoder(sparse=False)\n",
    "\n",
    "    # Use encoder_m0 feature names for consistency\n",
    "    encoder_mi.fit(df[categorical_columns])\n",
    "\n",
    "    Fi_scaled = create_dataset(df, current_date, scaler_mi, encoder_mi, df.columns)\n",
    "\n",
    "    # Ensure consistency in feature names\n",
    "    Fi_scaled.columns = Fi_scaled.columns.astype(str)\n",
    "\n",
    "    # Get missing features from the initial model\n",
    "    missing_features = set(F0.columns) - set(Fi_scaled.columns)\n",
    "\n",
    "    # Add missing features with zero values\n",
    "    for feature in missing_features:\n",
    "        Fi_scaled[feature] = 0\n",
    "\n",
    "    # Reorder columns to match the initial model\n",
    "    Fi_scaled = Fi_scaled[F0.columns]\n",
    "\n",
    "    Mi = KMeans(n_clusters=5)\n",
    "    Mi.fit(Fi_scaled)\n",
    "    c1_mi = Mi.predict(Fi_scaled)\n",
    "\n",
    "    # Predict clusters of Fi using the initial model M0\n",
    "    c1_m0 = M0.predict(Fi_scaled)\n",
    "\n",
    "    # Calculate adjusted_rand_score (ARI)\n",
    "    ari = adjusted_rand_score(c1_mi, c1_m0)\n",
    "    print(f\"ARI at {current_date}: {ari}\")\n",
    "\n",
    "    # Update the best ARI and its date if necessary\n",
    "    if ari > best_ari:\n",
    "        best_ari = ari\n",
    "        best_date = current_date\n",
    "\n",
    "    # Check if the model M0 becomes obsolete\n",
    "    if ari < 0.8:\n",
    "        print(f\"M0 becomes obsolete at {current_date}\")\n",
    "        F0_scaled = create_dataset(df, current_date, scaler_m0, encoder_m0, df.columns)\n",
    "\n",
    "        # Convert all column names to strings\n",
    "        F0_scaled.columns = F0_scaled.columns.astype(str)\n",
    "\n",
    "        M0.fit(F0_scaled)\n",
    "        print(\"M0 has been retrained.\")\n",
    "        # Retrain model M1 from the next day\n",
    "        retrain_m1 = True\n",
    "\n",
    "    # Retrain model M1 from the next day if necessary\n",
    "    if retrain_m1:\n",
    "        print(f\"Retraining M1 at {current_date + timedelta(days=1)}\")\n",
    "        Fi_scaled = create_dataset(df, current_date + timedelta(days=1), scaler_m0, encoder_m0, df.columns)\n",
    "\n",
    "        # Convert all column names to strings\n",
    "        Fi_scaled.columns = Fi_scaled.columns.astype(str)\n",
    "\n",
    "        M1.fit(Fi_scaled)\n",
    "        print(\"M1 has been retrained.\")\n",
    "        # Retrain model M2 from the next day\n",
    "        retrain_m2 = True\n",
    "\n",
    "    # Retrain model M2 from the next day if necessary\n",
    "    if retrain_m2:\n",
    "        print(f\"Retraining M2 at {current_date + timedelta(days=1)}\")\n",
    "        Fi_scaled = create_dataset(df, current_date + timedelta(days=1), scaler_m0, encoder_m0, df.columns)\n",
    "\n",
    "        # Convert all column names to strings\n",
    "        Fi_scaled.columns = Fi_scaled.columns.astype(str)\n",
    "\n",
    "        M2.fit(Fi_scaled)\n",
    "        print(\"M2 has been retrained.\")\n",
    "\n",
    "    # Move to the next period\n",
    "    current_date += timedelta(days=days_between_simulations)\n",
    "\n",
    "# Display the best ARI and its corresponding date after the loop\n",
    "print(f\"Best ARI: {best_ari} at {best_date}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ab808a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed8d8c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe63b75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f955c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b254ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19109e26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab7c9da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2f6653",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f263415e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79fdf67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3d3bde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab50ec8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cefc16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166882a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a9dc79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80ab789",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f189892",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173f715a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a971aa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528931a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a85d789",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7838313",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5594097f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53486226",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9481dd0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782fbeac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de020d14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d12db80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031b7cd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aabcea0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3664d707",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866f70bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636ba751",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bea44f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f8312d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653e91e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5477702",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd53c332",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9429921d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec166aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989df330",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5691ce9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c572aaff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118a46f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88bcdaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced5cb8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2274a467",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9c0d64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8945351d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb818ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0856351",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98297fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64ec25e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25427bd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f962e06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8052eca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40e7b99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b22d1aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bea7f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c644aa32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be8184a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad7ec50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d2df18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1b55333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARI à 2016-10-18 09:43:32: 0.4067109206654426\n",
      "Le modèle M0 devient obsolète à 2016-10-18 09:43:32\n",
      "Le modèle M0 a été réentraîné. Nouvelle durée d'obsolescence : 14 jours.\n",
      "Durée d'obsolescence actuelle : 14 jours\n",
      "ARI à 2016-11-01 09:43:32: 0.6389688469895931\n",
      "Le modèle M0 devient obsolète à 2016-11-01 09:43:32\n",
      "Le modèle M0 a été réentraîné. Nouvelle durée d'obsolescence : 28 jours.\n",
      "Durée d'obsolescence actuelle : 28 jours\n",
      "ARI à 2016-11-15 09:43:32: 0.6763564333097826\n",
      "Le modèle M0 devient obsolète à 2016-11-15 09:43:32\n",
      "Le modèle M0 a été réentraîné. Nouvelle durée d'obsolescence : 42 jours.\n",
      "Durée d'obsolescence actuelle : 42 jours\n",
      "ARI à 2016-11-29 09:43:32: 0.9786997645460459\n",
      "Durée d'obsolescence actuelle : 42 jours\n",
      "ARI à 2016-12-13 09:43:32: 0.9025067191315194\n",
      "Durée d'obsolescence actuelle : 42 jours\n",
      "ARI à 2016-12-27 09:43:32: 0.48225094061835433\n",
      "Le modèle M0 devient obsolète à 2016-12-27 09:43:32\n",
      "Le modèle M0 a été réentraîné. Nouvelle durée d'obsolescence : 56 jours.\n",
      "Durée d'obsolescence actuelle : 56 jours\n",
      "ARI à 2017-01-10 09:43:32: 0.6177318269353985\n",
      "Le modèle M0 devient obsolète à 2017-01-10 09:43:32\n",
      "Le modèle M0 a été réentraîné. Nouvelle durée d'obsolescence : 70 jours.\n",
      "Durée d'obsolescence actuelle : 70 jours\n",
      "ARI à 2017-01-24 09:43:32: 0.2526584249509318\n",
      "Le modèle M0 devient obsolète à 2017-01-24 09:43:32\n",
      "Le modèle M0 a été réentraîné. Nouvelle durée d'obsolescence : 84 jours.\n",
      "Durée d'obsolescence actuelle : 84 jours\n",
      "ARI à 2017-02-07 09:43:32: 0.2952989023903742\n",
      "Le modèle M0 devient obsolète à 2017-02-07 09:43:32\n",
      "Le modèle M0 a été réentraîné. Nouvelle durée d'obsolescence : 98 jours.\n",
      "Durée d'obsolescence actuelle : 98 jours\n",
      "ARI à 2017-02-21 09:43:32: 0.47912389102959296\n",
      "Le modèle M0 devient obsolète à 2017-02-21 09:43:32\n",
      "Le modèle M0 a été réentraîné. Nouvelle durée d'obsolescence : 112 jours.\n",
      "Durée d'obsolescence actuelle : 112 jours\n",
      "ARI à 2017-03-07 09:43:32: 0.5879305670604862\n",
      "Le modèle M0 devient obsolète à 2017-03-07 09:43:32\n",
      "Le modèle M0 a été réentraîné. Nouvelle durée d'obsolescence : 126 jours.\n",
      "Durée d'obsolescence actuelle : 126 jours\n",
      "ARI à 2017-03-21 09:43:32: 0.5637873321146654\n",
      "Le modèle M0 devient obsolète à 2017-03-21 09:43:32\n",
      "Le modèle M0 a été réentraîné. Nouvelle durée d'obsolescence : 140 jours.\n",
      "Durée d'obsolescence actuelle : 140 jours\n",
      "ARI à 2017-04-04 09:43:32: 0.6554976251829558\n",
      "Le modèle M0 devient obsolète à 2017-04-04 09:43:32\n",
      "Le modèle M0 a été réentraîné. Nouvelle durée d'obsolescence : 154 jours.\n",
      "Durée d'obsolescence actuelle : 154 jours\n",
      "ARI à 2017-04-18 09:43:32: 0.6794432047293023\n",
      "Le modèle M0 devient obsolète à 2017-04-18 09:43:32\n",
      "Le modèle M0 a été réentraîné. Nouvelle durée d'obsolescence : 168 jours.\n",
      "Durée d'obsolescence actuelle : 168 jours\n",
      "ARI à 2017-05-02 09:43:32: 0.541967161617834\n",
      "Le modèle M0 devient obsolète à 2017-05-02 09:43:32\n",
      "Le modèle M0 a été réentraîné. Nouvelle durée d'obsolescence : 182 jours.\n",
      "Durée d'obsolescence actuelle : 182 jours\n",
      "ARI à 2017-05-16 09:43:32: 0.531045575720182\n",
      "Le modèle M0 devient obsolète à 2017-05-16 09:43:32\n",
      "Le modèle M0 a été réentraîné. Nouvelle durée d'obsolescence : 196 jours.\n",
      "Durée d'obsolescence actuelle : 196 jours\n",
      "ARI à 2017-05-30 09:43:32: 0.9008617492550766\n",
      "Durée d'obsolescence actuelle : 196 jours\n",
      "ARI à 2017-06-13 09:43:32: 0.4886186893853056\n",
      "Le modèle M0 devient obsolète à 2017-06-13 09:43:32\n",
      "Le modèle M0 a été réentraîné. Nouvelle durée d'obsolescence : 210 jours.\n",
      "Durée d'obsolescence actuelle : 210 jours\n",
      "ARI à 2017-06-27 09:43:32: 0.9789993136755685\n",
      "Durée d'obsolescence actuelle : 210 jours\n",
      "ARI à 2017-07-11 09:43:32: 0.9633130430938656\n",
      "Durée d'obsolescence actuelle : 210 jours\n",
      "ARI à 2017-07-25 09:43:32: 0.7120876116478801\n",
      "Le modèle M0 devient obsolète à 2017-07-25 09:43:32\n",
      "Le modèle M0 a été réentraîné. Nouvelle durée d'obsolescence : 224 jours.\n",
      "Durée d'obsolescence actuelle : 224 jours\n",
      "ARI à 2017-08-08 09:43:32: 0.9564615517750038\n",
      "Durée d'obsolescence actuelle : 224 jours\n",
      "ARI à 2017-08-22 09:43:32: 0.9438240915342336\n",
      "Durée d'obsolescence actuelle : 224 jours\n",
      "ARI à 2017-09-05 09:43:32: 0.9604471176520594\n",
      "Durée d'obsolescence actuelle : 224 jours\n",
      "ARI à 2017-09-19 09:43:32: 0.9584270799271112\n",
      "Durée d'obsolescence actuelle : 224 jours\n",
      "ARI à 2017-10-03 09:43:32: 0.7553959016764126\n",
      "Le modèle M0 devient obsolète à 2017-10-03 09:43:32\n",
      "Le modèle M0 a été réentraîné. Nouvelle durée d'obsolescence : 238 jours.\n",
      "Durée d'obsolescence actuelle : 238 jours\n",
      "ARI à 2017-10-17 09:43:32: 0.985710462010075\n",
      "Durée d'obsolescence actuelle : 238 jours\n",
      "ARI à 2017-10-31 09:43:32: 0.9891715813277858\n",
      "Durée d'obsolescence actuelle : 238 jours\n",
      "ARI à 2017-11-14 09:43:32: 0.9036751564423393\n",
      "Durée d'obsolescence actuelle : 238 jours\n",
      "ARI à 2017-11-28 09:43:32: 0.6025628076510573\n",
      "Le modèle M0 devient obsolète à 2017-11-28 09:43:32\n",
      "Le modèle M0 a été réentraîné. Nouvelle durée d'obsolescence : 252 jours.\n",
      "Durée d'obsolescence actuelle : 252 jours\n",
      "ARI à 2017-12-12 09:43:32: 0.7440965847072957\n",
      "Le modèle M0 devient obsolète à 2017-12-12 09:43:32\n",
      "Le modèle M0 a été réentraîné. Nouvelle durée d'obsolescence : 266 jours.\n",
      "Durée d'obsolescence actuelle : 266 jours\n",
      "ARI à 2017-12-26 09:43:32: 0.9908092850035404\n",
      "Durée d'obsolescence actuelle : 266 jours\n",
      "ARI à 2018-01-09 09:43:32: 0.9124410366721144\n",
      "Durée d'obsolescence actuelle : 266 jours\n",
      "ARI à 2018-01-23 09:43:32: 0.5479151929366376\n",
      "Le modèle M0 devient obsolète à 2018-01-23 09:43:32\n",
      "Le modèle M0 a été réentraîné. Nouvelle durée d'obsolescence : 280 jours.\n",
      "Durée d'obsolescence actuelle : 280 jours\n",
      "ARI à 2018-02-06 09:43:32: 0.904193903652643\n",
      "Durée d'obsolescence actuelle : 280 jours\n",
      "ARI à 2018-02-20 09:43:32: 0.9898863291531164\n",
      "Durée d'obsolescence actuelle : 280 jours\n",
      "ARI à 2018-03-06 09:43:32: 0.8695809955465444\n",
      "Durée d'obsolescence actuelle : 280 jours\n",
      "ARI à 2018-03-20 09:43:32: 0.7711287302737047\n",
      "Le modèle M0 devient obsolète à 2018-03-20 09:43:32\n",
      "Le modèle M0 a été réentraîné. Nouvelle durée d'obsolescence : 294 jours.\n",
      "Durée d'obsolescence actuelle : 294 jours\n",
      "ARI à 2018-04-03 09:43:32: 0.33978721022291475\n",
      "Le modèle M0 devient obsolète à 2018-04-03 09:43:32\n",
      "Le modèle M0 a été réentraîné. Nouvelle durée d'obsolescence : 308 jours.\n",
      "Durée d'obsolescence actuelle : 308 jours\n",
      "ARI à 2018-04-17 09:43:32: 0.9625102271214351\n",
      "Durée d'obsolescence actuelle : 308 jours\n",
      "ARI à 2018-05-01 09:43:32: 0.5487547594757505\n",
      "Le modèle M0 devient obsolète à 2018-05-01 09:43:32\n",
      "Le modèle M0 a été réentraîné. Nouvelle durée d'obsolescence : 322 jours.\n",
      "Durée d'obsolescence actuelle : 322 jours\n",
      "ARI à 2018-05-15 09:43:32: 0.7627737681640555\n",
      "Le modèle M0 devient obsolète à 2018-05-15 09:43:32\n",
      "Le modèle M0 a été réentraîné. Nouvelle durée d'obsolescence : 336 jours.\n",
      "Durée d'obsolescence actuelle : 336 jours\n",
      "ARI à 2018-05-29 09:43:32: 0.5523289347484222\n",
      "Le modèle M0 devient obsolète à 2018-05-29 09:43:32\n",
      "Le modèle M0 a été réentraîné. Nouvelle durée d'obsolescence : 350 jours.\n",
      "Durée d'obsolescence actuelle : 350 jours\n",
      "ARI à 2018-06-12 09:43:32: 0.5582216893909825\n",
      "Le modèle M0 devient obsolète à 2018-06-12 09:43:32\n",
      "Le modèle M0 a été réentraîné. Nouvelle durée d'obsolescence : 364 jours.\n",
      "Durée d'obsolescence actuelle : 364 jours\n",
      "ARI à 2018-06-26 09:43:32: 0.3625645132084579\n",
      "Le modèle M0 devient obsolète à 2018-06-26 09:43:32\n",
      "Le modèle M0 a été réentraîné. Nouvelle durée d'obsolescence : 378 jours.\n",
      "Durée d'obsolescence actuelle : 378 jours\n",
      "ARI à 2018-07-10 09:43:32: 0.9933129137567831\n",
      "Durée d'obsolescence actuelle : 378 jours\n",
      "ARI à 2018-07-24 09:43:32: 0.7467900707082022\n",
      "Le modèle M0 devient obsolète à 2018-07-24 09:43:32\n",
      "Le modèle M0 a été réentraîné. Nouvelle durée d'obsolescence : 392 jours.\n",
      "Durée d'obsolescence actuelle : 392 jours\n",
      "ARI à 2018-08-07 09:43:32: 0.9935615659370497\n",
      "Durée d'obsolescence actuelle : 392 jours\n",
      "ARI à 2018-08-21 09:43:32: 0.7428380096538678\n",
      "Le modèle M0 devient obsolète à 2018-08-21 09:43:32\n",
      "Le modèle M0 a été réentraîné. Nouvelle durée d'obsolescence : 406 jours.\n",
      "Durée d'obsolescence actuelle : 406 jours\n",
      "Meilleur ARI : 0.9935615659370497 à 2018-08-07 09:43:32\n",
      "Durée d'obsolescence totale : 406 jours\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Charger le DataFrame initial (en supposant que vous avez un DataFrame nommé df_cluster_sample)\n",
    "df = df_cluster_sample.copy()\n",
    "\n",
    "# Colonnes à supprimer\n",
    "colonnes_a_supprimer = ['seller_zip_code_prefix', 'seller_city', 'seller_state', 'customer_geo_lat', 'customer_geo_lng',\n",
    "                   'seller_geo_lat', 'seller_geo_lng', 'time_between_orders_same_customer',\n",
    "                   'days_between_orders_same_customer', 'hours_between_orders_same_customer',\n",
    "                   'time_between_orders_all', 'days_between_orders_all', 'hours_between_orders_all',\n",
    "                   'order_id', 'product_id', 'seller_id', 'customer_id', 'customer_unique_id']\n",
    "\n",
    "# Supprimer les colonnes spécifiées\n",
    "df = df.drop(columns=colonnes_a_supprimer)\n",
    "\n",
    "# Fonction pour créer un ensemble de données jusqu'à une date donnée\n",
    "def creer_ensemble_de_donnees(df, date_fin, scaler, encodeur, noms_caracteristiques_de_base):\n",
    "    ensemble_de_donnees = df[df['order_approved_at'] <= date_fin].drop('order_approved_at', axis=1)\n",
    "    \n",
    "    # Séparer les colonnes numériques et catégorielles\n",
    "    colonnes_numeriques = ensemble_de_donnees.select_dtypes(include=np.number).columns\n",
    "    colonnes_catégorielles = ensemble_de_donnees.select_dtypes(exclude=np.number).columns\n",
    "\n",
    "    # Ajuster et transformer les colonnes numériques\n",
    "    ensemble_de_donnees[colonnes_numeriques] = scaler.fit_transform(ensemble_de_donnees[colonnes_numeriques])\n",
    "\n",
    "    # Transformer les colonnes catégorielles et créer un nouveau DataFrame\n",
    "    cat_transformed = pd.DataFrame(encodeur.fit_transform(ensemble_de_donnees[colonnes_catégorielles]),\n",
    "                                   columns=encodeur.get_feature_names_out(colonnes_catégorielles), index=ensemble_de_donnees.index)\n",
    "\n",
    "    # Concaténer les colonnes numériques et catégorielles transformées\n",
    "    ensemble_de_donnees = pd.concat([ensemble_de_donnees[colonnes_numeriques], cat_transformed], axis=1)\n",
    "\n",
    "    # Assurer la cohérence dans les noms des caractéristiques\n",
    "    ensemble_de_donnees.columns = ensemble_de_donnees.columns.astype(str)\n",
    "\n",
    "    # Obtenir les caractéristiques manquantes des noms de caractéristiques de base\n",
    "    caractéristiques_manquantes = set(noms_caracteristiques_de_base) - set(ensemble_de_donnees.columns)\n",
    "\n",
    "    # Ajouter les caractéristiques manquantes avec des zéros comme valeurs\n",
    "    for caractéristique in caractéristiques_manquantes:\n",
    "        ensemble_de_donnees[caractéristique] = 0\n",
    "\n",
    "    # Réorganiser les colonnes pour correspondre aux noms de caractéristiques de base\n",
    "    ensemble_de_donnees = ensemble_de_donnees[noms_caracteristiques_de_base]\n",
    "\n",
    "    return ensemble_de_donnees\n",
    "\n",
    "# Entraînement initial du modèle sur F0 (en supposant que T0 est le début du jeu de données)\n",
    "scaler_m0 = StandardScaler()\n",
    "encodeur_m0 = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Ajuster encodeur_m0 sur l'ensemble du jeu de données pour obtenir les noms de caractéristiques\n",
    "colonnes_catégorielles = df.select_dtypes(exclude=np.number).columns\n",
    "encodeur_m0.fit(df[colonnes_catégorielles])\n",
    "\n",
    "F0 = creer_ensemble_de_donnees(df, df['order_approved_at'].min() + timedelta(weeks=2), scaler_m0, encodeur_m0, df.columns)  # 2 semaines à partir de la date de début\n",
    "\n",
    "# Convertir tous les noms de colonnes en chaînes\n",
    "F0.columns = F0.columns.astype(str)\n",
    "\n",
    "m0 = KMeans(n_clusters=5)\n",
    "m0.fit(F0)\n",
    "c0_m0 = m0.predict(F0)\n",
    "\n",
    "# Itération à travers les périodes\n",
    "jours_entre_les_simulations = 14\n",
    "date_actuelle = df['order_approved_at'].min() + timedelta(weeks=2)\n",
    "\n",
    "# Initialiser les variables pour stocker le meilleur ARI, sa date correspondante, et la durée d'obsolescence\n",
    "meilleur_ari = 0\n",
    "meilleure_date = None\n",
    "duree_obsolescence = 0\n",
    "\n",
    "# Initialiser les modèles M1, M2\n",
    "M1 = KMeans(n_clusters=5)\n",
    "M2 = KMeans(n_clusters=5)\n",
    "\n",
    "while date_actuelle <= df['order_approved_at'].max():\n",
    "    # Créer l'ensemble de données Fi\n",
    "    Fi = creer_ensemble_de_donnees(df, date_actuelle, scaler_m0, encodeur_m0, df.columns)\n",
    "    \n",
    "    # Convertir tous les noms de colonnes en chaînes\n",
    "    Fi.columns = Fi.columns.astype(str)\n",
    "\n",
    "    # Entraîner un nouveau modèle Mi sur Fi\n",
    "    scaler_mi = StandardScaler()\n",
    "    encodeur_mi = OneHotEncoder(sparse=False)\n",
    "\n",
    "    # Utiliser les noms de caractéristiques de l'encodeur_m0 pour assurer la cohérence\n",
    "    encodeur_mi.fit(df[colonnes_catégorielles])\n",
    "\n",
    "    Fi_mise_a_l_echelle = creer_ensemble_de_donnees(df, date_actuelle, scaler_mi, encodeur_mi, df.columns)\n",
    "\n",
    "    # Assurer la cohérence dans les noms des caractéristiques\n",
    "    Fi_mise_a_l_echelle.columns = Fi_mise_a_l_echelle.columns.astype(str)\n",
    "\n",
    "    # Obtenir les caractéristiques manquantes du modèle initial\n",
    "    caractéristiques_manquantes = set(F0.columns) - set(Fi_mise_a_l_echelle.columns)\n",
    "\n",
    "    # Ajouter les caractéristiques manquantes avec des zéros comme valeurs\n",
    "    for caractéristique in caractéristiques_manquantes:\n",
    "        Fi_mise_a_l_echelle[caractéristique] = 0\n",
    "\n",
    "    # Réorganiser les colonnes pour correspondre au modèle initial\n",
    "    Fi_mise_a_l_echelle = Fi_mise_a_l_echelle[F0.columns]\n",
    "\n",
    "    # Utiliser le modèle M0\n",
    "    c1_m0 = m0.predict(Fi_mise_a_l_echelle)\n",
    "\n",
    "    # Sélectionner le modèle en fonction de la durée d'obsolescence\n",
    "    if duree_obsolescence == 0:\n",
    "        Mi = M1\n",
    "    elif duree_obsolescence == 14:\n",
    "        Mi = M2\n",
    "    # Ajouter des conditions pour d'autres modèles si nécessaire\n",
    "\n",
    "    # Entraîner le modèle Mi sur Fi\n",
    "    Mi.fit(Fi_mise_a_l_echelle)\n",
    "    c1_mi = Mi.predict(Fi_mise_a_l_echelle)\n",
    "\n",
    "    # Calculer l'ARI\n",
    "    ari = adjusted_rand_score(c1_mi, c1_m0)\n",
    "    print(f\"ARI à {date_actuelle}: {ari}\")\n",
    "\n",
    "    # Mettre à jour le meilleur ARI, sa date et la durée d'obsolescence si nécessaire\n",
    "    if ari > meilleur_ari:\n",
    "        meilleur_ari = ari\n",
    "        meilleure_date = date_actuelle\n",
    "\n",
    "    # Déterminer si le modèle a besoin d'être réentraîné\n",
    "    if ari < 0.8:\n",
    "        print(f\"Le modèle M0 devient obsolète à {date_actuelle}\")\n",
    "        duree_obsolescence += jours_entre_les_simulations  # Ajouter la durée d'obsolescence\n",
    "        F0_mise_a_l_echelle = creer_ensemble_de_donnees(df, date_actuelle, scaler_m0, encodeur_m0, df.columns)\n",
    "        \n",
    "        # Convertir tous les noms de colonnes en chaînes\n",
    "        F0_mise_a_l_echelle.columns = F0_mise_a_l_echelle.columns.astype(str)\n",
    "        \n",
    "        m0.fit(F0_mise_a_l_echelle)\n",
    "        c0_m0 = m0.predict(F0_mise_a_l_echelle)\n",
    "        print(f\"Le modèle M0 a été réentraîné. Nouvelle durée d'obsolescence : {duree_obsolescence} jours.\")\n",
    "\n",
    "    # Passer à la période suivante\n",
    "    date_actuelle += timedelta(days=jours_entre_les_simulations)\n",
    "\n",
    "    # Afficher la durée d'obsolescence si elle existe\n",
    "    if duree_obsolescence > 0 and (duree_obsolescence % 14 == 0 or date_actuelle > df['order_approved_at'].max()):\n",
    "        print(f\"Durée d'obsolescence actuelle : {duree_obsolescence} jours\")\n",
    "\n",
    "# Afficher le meilleur ARI, sa date correspondante, et la durée d'obsolescence après la boucle\n",
    "print(f\"Meilleur ARI : {meilleur_ari} à {meilleure_date}\")\n",
    "print(f\"Durée d'obsolescence totale : {duree_obsolescence} jours\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f37b82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a195da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8df0cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2c22b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c9d251",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0026b1aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade90f1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3853b3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca36def5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59066fdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8b3901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af62991",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d58820c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd09ef2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63377d6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87732786",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76114531",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21950ce1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2609f42d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4e5fc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e83223",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d46472",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11bbfe5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a26dccb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0c3915",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a54c748",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dcea5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a9f8aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0f8f82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122e8be7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a269cfad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cd489e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b961b220",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47251cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8efbd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c929f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0b7fcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b8f9c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717ad1ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b1bc40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21ae1bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95687ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838a4fc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b48392",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace6b0fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d273f796",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020e71fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3252c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85e08fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0dcd33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1805768e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3dbc4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27cf0ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068724fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2003fb6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e28064",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89440e10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb84dcf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed6bd8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e56dda5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08ef0ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4353a5c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967b81d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef39ab0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159eb61f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca003ecc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff7e6de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda5c168",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2042b348",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab078a69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d3fade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3849cd2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cb998e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c61f6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fbe16e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e398ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ba1e7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
